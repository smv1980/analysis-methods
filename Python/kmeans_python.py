# -*- coding: utf-8 -*-
"""Kmeans-Python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H6tc8oS5MI9pTqXZYNP8xdV6d_XqeJ5f

# **Import Data from Kaggle**

Data set used was uploaded to Kaggle by Zubair Mustafa.
The data is called: Shopping Mall Customer Segmentation Data
"""

import kagglehub

# Download Last Version of https://www.kaggle.com/datasets/zubairmustafa/shopping-mall-customer-segmentation-data?resource=download
path = kagglehub.dataset_download("zubairmustafa/shopping-mall-customer-segmentation-data")

print("Path to dataset files:", path)

"""# **Loading Data**"""

import pandas as pd
data = pd.read_csv('/kaggle/input/shopping-mall-customer-segmentation-data/Shopping Mall Customer Segmentation Data .csv')

"""# **Exploratory Analysis**

## **Null and Duplicated Data**
"""

# Variables and Type
data.info()

# Five first registers
data.head()

# Preliminar Analysis
print(f'Total Registers (rows): {data.shape[0]}')
print(f'Total Variables (columns): {data.shape[1]}')
print(f'Variable Names: {data.columns.tolist()}')
print(f'Null Values: {sum(data.isnull().sum())}')
print(f'Duplicated Values: {data.duplicated().sum()}')

"""The database has 15079 registers and 5 variables:
* "Customer ID"
* "Age"
* "Gender"
* "Annual Income"
* "Spending Score": assigned based on customer behaviour and purchasing data (Mustafa, 2024)

No null or duplicated values.

## **Check consistency of categorical data**
"""

data["Gender"] = data["Gender"].astype("category")

data["Gender"].unique()

"""## **Outlier identification and management**"""

#Function to find and eliminate outlierar in each column (all values that are more than n standard deviation from the mean)
def remove_outliers(df,columns,n_std):
    outliers = pd.DataFrame(columns=df.columns)
    for col in columns:
        if pd.api.types.is_numeric_dtype(df[col]): #Verify if column is numeric before calculating mean and standard deviation
            print('Working on column: {}'.format(col))
            mean = df[col].mean()
            sd = df[col].std()

            # Outlier Identification
            condition = (df[col] > mean + (n_std * sd))
            outliers = pd.concat([outliers, df[condition]], ignore_index=True)

            # Removal of outliers from the original dataframe
            df = df[(df[col] <= mean+(n_std*sd))]
    return df, outliers

# Create a variable columns with the columns' names
columns = data.columns

# Apply the created function
cleaned_data, outliers = remove_outliers(data, columns, 3)     # all values that are more than 3 standard deviations from the mean
cleaned_data.reset_index(drop=True, inplace=True)

print("\nOutliers eliminados:")
print(outliers)

"""## **General Statistics**"""

import seaborn as sns # Visualization library developed on matplotlib (better graphs)
import matplotlib.pyplot as plt # Specialized graphs library

data.describe()

# Correlation Matrix
plt.figure(figsize=(12, 7))
numerical_data = data.select_dtypes(include=['number']) # Select only numerical columns
sns.heatmap(numerical_data.corr(), annot = True, vmin = -1, vmax = 1)
plt.show()

"""Very weak correlation between the numeric variables.

### **Age**
"""

# Age statistics grouped data by Gender
pd.options.display.max_columns = None
data.groupby(['Gender'])['Age'].describe()

# Total of buyers by gender
plt.subplot(1,2,1)
plt.title('Individuals by Gender (in Units)', fontsize=14)
ax = sns.countplot(x="Gender", data=data, order=data['Gender'].value_counts().index, alpha=0.3)
for p in ax.patches:
   ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.30, p.get_height()+2))
plt.xlabel(None)
plt.ylabel(None)

# Total buyers by gender in Percentage
plt.subplot(1,2,2)
plt.title('Individuals by Gender (in %)',fontsize=14)
data['Gender'].value_counts().plot(kind='pie', legend=None, ylabel='', counterclock=False, startangle=150, wedgeprops={'alpha':0.3, 'edgecolor' : 'black','linewidth': 2, 'antialiased': True}, autopct='%1.1f%%')

plt.show()

"""We a see a higher amount of male registers."""

# Function to generate age groups
def age_group_function(data):

    if (data['Age'] >= 100):                               # Group older than 100 years old
        return '[100<]'

    elif (data['Age'] < 100) and (data['Age'] >= 90):       # Group between 90 and 100 years old
        return '[90, 100]'

    elif (data['Age'] < 90) and (data['Age'] >= 80):        # Group between 80 y 90 years old
        return '[80, 90]'

    elif (data['Age'] < 80) and (data['Age'] >= 70):        # Group between 70 y 80 years old
        return '[70, 80]'

    elif (data['Age'] <= 70) and (data['Age'] >= 60):       # Group between 60 y 70 years old
        return '[60, 70]'

    elif (data['Age'] <= 60) and (data['Age'] >= 50):       # Group between 50 y 60 years old
        return '[50, 60]'

    elif (data['Age'] <= 50) and (data['Age'] >= 40):       # Group between 40 y 50 years old
        return '[40, 50]'

    elif (data['Age'] <= 40) and (data['Age'] >= 30):       # Group between 30 y 40 years old
        return '[30, 40]'

    elif (data['Age'] <= 30) and (data['Age'] >= 20):       # Group between 20 y 30 years old
        return '[20, 30]'

    elif (data['Age'] <= 20) and (data['Age'] >= 10):       # Group between 10 y 20 years old
        return '[10, 20]'

    elif (data['Age'] < 10):                              # Group younger than 10 years old
        return '[0-10]'

# Applying the function to generate column age_group
data['age_group'] = data.apply(age_group_function, axis = 1)

# Count the frequency of each age group for each gender
age_group_counts = data.groupby(['age_group', 'Gender'])['Gender'].count().unstack()
age_group_counts

# Create Population Pyramid
fig, ax = plt.subplots(figsize=(10, 6))

# Counts of females and males
female_counts = age_group_counts['Female'].values
male_counts = age_group_counts['Male'].values

# Graphs
ax.barh(age_group_counts.index, female_counts, color='pink', label='Female')
ax.barh(age_group_counts.index, -male_counts, color='aquamarine', label='Male')

# Add values to bars
for i, count in enumerate(female_counts):
    ax.text(count + 2, i, str(count), color='red', va='center', fontsize=10)

for i, count in enumerate(male_counts):
    ax.text(-count - 152, i, str(count), color='green', va='center', fontsize=10)

# Axis limits
ax.set_xlim(-max(male_counts)-300, max(female_counts)+300)

# Only write value 0 on x-ticks
ax.set_xticks([0])

# Labels and Title
ax.set_xlabel('Amount of Buyers')
ax.set_ylabel('Age Group')
ax.set_title('Population Pyramid')
ax.legend()

plt.show()

"""### **Annual Income**"""

data.groupby(['Gender'])['Annual Income'].describe()

import plotly.express as px #Improved visualization (interactive)

fig1 = px.box(data, y="Annual Income")
fig2 = px.box(data, x="Gender", y="Annual Income", color="Gender")

import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Create subplot with 1 row and 2 columns
fig = make_subplots(rows=1, cols=2, subplot_titles=('Annual Income', 'Annual Income by Gender'))

# Add traces from your existing figures
fig.add_trace(fig1.data[0], row=1, col=1)
fig.add_trace(fig2.data[0], row=1, col=2)
fig.add_trace(fig2.data[1], row=1, col=2)

# Update layout
fig.update_layout(height=400, width=800, showlegend=False)
fig.show()

annual_income_by_age_group = data.groupby(['age_group','Gender'])['Annual Income'].sum() / data.groupby(['age_group','Gender'])['Annual Income'].count() * 100.0
annual_income_by_age_group = annual_income_by_age_group.reset_index()
annual_income_by_age_group.columns = ['age_group', 'Gender', 'Avg_Annual_Income']

fig = px.bar(
    annual_income_by_age_group,
    x='age_group',
    y='Avg_Annual_Income',
    color='Gender',
    barmode='group',
    title='Average Annual Income by Age Group and Gender',
    labels={'age_group': 'Age Group', 'Avg_Annual_Income': 'Average Annual Income ($)'},
    text='Avg_Annual_Income',
)

fig.update_traces(texttemplate='%{text:.0f}', textposition='outside')
fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide',plot_bgcolor='white',)
fig.show()

fig = px.line(
    annual_income_by_age_group,
    x='age_group',
    y='Avg_Annual_Income',
    color='Gender',
    markers=True,  # Adds markers to points
    title='Trend of Average Annual Income by Age Group',
    labels={'age_group': 'Age Group', 'Avg_Annual_Income': 'Average Annual Income ($)'},
)

fig.update_traces(line=dict(width=2.5))  # Make lines thicker
fig.show()

"""### **Spending Score**"""

fig1 = px.box(data, y="Spending Score")
fig2 = px.box(data, x="Gender", y="Spending Score", color="Gender")

# Create subplot with 1 row and 2 columns
fig = make_subplots(rows=1, cols=2, subplot_titles=('Spending Score', 'Spending Score by Gender'))

# Add traces from your existing figures
fig.add_trace(fig1.data[0], row=1, col=1)
fig.add_trace(fig2.data[0], row=1, col=2)
fig.add_trace(fig2.data[1], row=1, col=2)

# Update layout
fig.update_layout(height=400, width=800, showlegend=False)
fig.show()

spending_score_by_age_group = data.groupby(['age_group','Gender'], observed=True)['Spending Score'].sum() / data.groupby(['age_group','Gender'], observed=True)['Spending Score'].count() * 100.0
spending_score_by_age_group = spending_score_by_age_group.reset_index()
spending_score_by_age_group.columns = ['age_group', 'Gender', 'Avg_Spending Score']

fig = px.bar(
    spending_score_by_age_group,
    x='age_group',
    y='Avg_Spending Score',
    color='Gender',
    barmode='group',
    title='Average Spending Score by Age Group and Gender',
    labels={'age_group': 'Age Group', 'Avg_Spending Score': 'Average Spending Score'},
    text='Avg_Spending Score',
)

fig.update_traces(texttemplate='%{text:.0f}', textposition='outside')
fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide',plot_bgcolor='white',)
fig.show()

fig = px.line(
    spending_score_by_age_group,
    x='age_group',
    y='Avg_Spending Score',
    color='Gender',
    markers=True,
    title='Trend of Average Spending Score by Age Group',
    labels={'age_group': 'Age Group', 'Avg_Spending Score': 'Average Spending Score'},
)

fig.update_traces(line=dict(width=2.5))
fig.show()

"""# **Kmeans**"""

# Codify the categorical variable Gender (to convert it into numeric)
data["Gender"] = data["Gender"].cat.codes
data.head()

"""Gender = 0 = Female

Gender = 1 = Male

## **a) Normalization**
"""

numeric_data = data.select_dtypes(include=['number']) # Select only numeric columns
data_norm = (numeric_data - numeric_data.min()) / (numeric_data.max() - numeric_data.min())
data_norm['Gender'] = data['Gender']  # add Gender column back
data_norm.head()

"""## **b) Number of Clusters Determination with Elbow Method**"""

from sklearn.cluster import KMeans

# Crear empty variable to store values of WCSS that are calculating when using the loop
wcss = []

# Loop to create different amount of clusters asigning values to variable i, in a range in 3
for i in range(1,11):
  kmeans = KMeans(n_clusters = i, max_iter=300, random_state=2) # create a kmean model, indicating with i that the amount of clusters will change as i takes the values between 1 and 10, with a maximum of 300 iterations for kmeans
  kmeans.fit(data_norm) # apply the created model to the normalized dataframe
  wcss.append(kmeans.inertia_) # value of WCS corresponding to the model with i clusters and add it to the empty variable

# print on screen the values of WCS generated with the loop
print(f"\n Valores de WCSS para distintas cantidades de clusters: {wcss}")

# luego, graficamos los resultados de WCSS para formar el codo de Jambú y tomar una decisión
plt.plot(range(1,11),wcss)
plt.title("Elbow method")
plt.xlabel("Number of Clusters")
plt.ylabel("WCSS") # indicador de inercia
plt.show()

"""## **c) KneeLocator**"""

# Initialize KneeLocator
!pip install kneed
from kneed import KneeLocator
kl = KneeLocator(range(1, 11), wcss, curve="convex", direction="decreasing")

# Print the elbow point
print('KneeLocator es igual a ', kl.elbow)

"""## **d) Silhouette Method**"""

## Método Silhouette
from sklearn.metrics import silhouette_score

silhouette_coef = []

for cluster in range(2,16):
    kmeans = KMeans(n_clusters = cluster, init = 'k-means++', random_state = 1)
    kmeans.fit(data_norm)
    score = silhouette_score(data_norm, kmeans.labels_)
    silhouette_coef.append(score)

silhouette_coef

## Silhouette Coefficient Graph

plt.figure(figsize=(8,5))
plt.plot(range(2,16), silhouette_coef)
plt.xticks(range(2,16))
plt.title('Silhouette Coefficient for Ideal Number of Clusters', fontsize=14)
plt.xlabel('No. of Clusters')
plt.ylabel('Silhhouette Coef')
plt.show()

"""## **KMeans with two clusters and 300 iterations**"""

# Create the model
clustering = KMeans(n_clusters = 2, max_iter = 300, random_state = 2)

# Apply model to dataframe
clustering.fit(data_norm)

# Create new column on the dataframe that indicates to which cluster belong the customer
data["KMeans_Clusters"] = clustering.labels_

# Dataframe with new column
data.head()

# Statistical analysis
pd.set_option('display.max_rows', None)
data.groupby("KMeans_Clusters").describe().T

# Graphical representation of original groups versus created clusters
# ==============================================================================
import matplotlib.pyplot as plt  # Import the matplotlib.pyplot module
import numpy as np

fig, ax = plt.subplots(1, 2, figsize=(10, 4))

# Assuming 'KMeans_Clusters' column in 'data' represents original cluster labels
# Replace 'data_norm' with the appropriate DataFrame containing original data if different
# Replace 'Annual Income' and 'Spending Score' with actual column names if different
for i in np.unique(data['KMeans_Clusters']):
    ax[0].scatter(
        x=data_norm[data['KMeans_Clusters'] == i]['Annual Income'],
        y=data_norm[data['KMeans_Clusters'] == i]['Spending Score'],
        c=plt.rcParams['axes.prop_cycle'].by_key()['color'][i],
        marker='o',
        edgecolor='black',
        label=f"Grupo {i}"
    )

ax[0].set_title('Clusters generados por Kmeans')
ax[0].legend()

# For the second plot, you need to define 'y_predict', 'X_scaled', and 'modelo_kmeans'
# Assuming 'clustering' from previous cell holds the KMeans model
y_predict = clustering.labels_
X_scaled = data_norm[['Annual Income', 'Spending Score']]  # Assuming these are the features used for clustering
modelo_kmeans = clustering  # Assign the KMeans model to 'modelo_kmeans'

for i in np.unique(y_predict):
    ax[1].scatter(
        x=X_scaled[y_predict == i]['Annual Income'],
        y=X_scaled[y_predict == i]['Spending Score'],
        c=plt.rcParams['axes.prop_cycle'].by_key()['color'][i],
        marker='o',
        edgecolor='black',
        label=f"Cluster {i}"
    )

ax[1].scatter(
    x=modelo_kmeans.cluster_centers_[:, 0],
    y=modelo_kmeans.cluster_centers_[:, 1],
    c='black',
    s=200,
    marker='*',
    label='centroides'
)
ax[1].set_title('Clusters generados por Kmeans')
ax[1].legend()

plt.show()  # Add plt.show() to display the plot

# Clusters Graphs
plt.scatter(data_norm.iloc[:, 0], data_norm.iloc[:, 1], c=clustering.labels_, cmap='viridis', marker='o', edgecolor='k')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'black', label = 'Centroids')
plt.title('KMeans Clustering')
plt.xlabel('Speding Score normalizado')
plt.ylabel('Annual Income normalizado')
plt.colorbar(label='Cluster Label')
plt.show()

# 3D Plot
import plotly.express as px

data_norm['KMeans_Clusters'] = data['KMeans_Clusters']

fig_3d = px.scatter_3d(
    data_norm,
    x='Age',
    y='Annual Income',
    z='Spending Score',
    color='KMeans_Clusters',
    title='Customer Segments - 3D View',
    labels={
        'Age': 'Age',
        'Annual Income': 'Annual Income',
        'Spending Score': 'Spending Score'
    },
    color_continuous_scale='viridis'
)

fig_3d.update_layout(
    scene = dict(
        xaxis_title='Age',
        yaxis_title='Annual Income',
        zaxis_title='Spending Score'
    ),
    title={'y':0.95, 'x':0.5, 'xanchor': 'center', 'yanchor': 'top'},
    height=700,
    width=900
)
fig_3d.show()

"""# **References**

Mustafa, Z. 2024. Shopping Mall Customer Segmentation Data. https://www.kaggle.com/datasets/zubairmustafa/shopping-mall-customer-segmentation-data?resource=download. Consultado el 22 de marzo de 2025.
"""